<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="《Active Learning for Deep Semantic Parsing》阅读笔记"><meta name="keywords" content="NLP,Active Learning"><meta name="author" content="yym6472"><meta name="copyright" content="yym6472"><title>《Active Learning for Deep Semantic Parsing》阅读笔记 | yym6472's Blog</title><link rel="shortcut icon" href="/favicon-256.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"G2KYQO0W55","apiKey":"f8377236a1dbdcb6cfe6bcce269cbc82","indexName":"blog","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#要解决的问题"><span class="toc-number">1.</span> <span class="toc-text"> 要解决的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#标注数据的两种方式"><span class="toc-number">2.</span> <span class="toc-text"> 标注数据的两种方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基础模型"><span class="toc-number">3.</span> <span class="toc-text"> 基础模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#主动学习方法"><span class="toc-number">4.</span> <span class="toc-text"> 主动学习方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#针对传统数据集的主动学习策略"><span class="toc-number">4.1.</span> <span class="toc-text"> 针对传统数据集的主动学习策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#针对overnight数据集的主动学习策略"><span class="toc-number">4.2.</span> <span class="toc-text"> 针对overnight数据集的主动学习策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实验"><span class="toc-number">5.</span> <span class="toc-text"> 实验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#待思考的点"><span class="toc-number">6.</span> <span class="toc-text"> 待思考的点</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://i.loli.net/2019/04/27/5cc4218c74e0e.jpg"></div><div class="author-info__name text-center">yym6472</div><div class="author-info__description text-center"></div><div class="follow-button"><a href="https://github.com/yym6472">Follow Me on GitHub</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">5</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">6</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">4</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://molunerfinn.com/">MARKSZのBlog (Theme Auther's Blog)</a><a class="author-info-links__name text-center" href="https://pris-nlp.github.io/">BUPT PRIS Lab, NLP Group</a><a class="author-info-links__name text-center" href="https://helicqin.github.io/">Helicqin's Blog</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://i.loli.net/2019/04/27/5cc456373162f.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">yym6472's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a><a class="site-page" href="/contact">Contact</a></span></div><div id="post-info"><div id="post-title">《Active Learning for Deep Semantic Parsing》阅读笔记</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-04-26</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/学习/">学习</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/学习/论文阅读笔记/">论文阅读笔记</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1.8k</span><span class="post-meta__separator">|</span><span>Reading time: 5 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="要解决的问题"><a class="markdownIt-Anchor" href="#要解决的问题"></a> 要解决的问题</h2>
<p>语义分析任务（Semantic Parsing）指的是：从给定的自然语言查询（query）中提取有效信息，将其转换为一个逻辑范式（Logical Form, LF）。也就是需要将表述方式十分随意的句子转换成一个结构化的、计算机能理解的形式语言句子。需要转换成的LF的形式取决于具体任务。下图是对应到某些任务（数据集）中的<strong>自然语言 - LF</strong>的样例：<br>
<img src="http://imglf5.nosdn0.126.net/img/Y3cva2JCQ0tUWi91TkhqKzN0OUdkQWFONkhOSHZmaS9JUXNtTFBnQklEZXdxcGFLcEtkeU1RPT0.jpg" alt="自然语言-LF的样例"><br>
可以看到被转换的LF也是一个句子（序列），因此其本质上也是一个seq2seq的任务。</p>
<p>这类任务往往需要花费巨大的代价对数据进行标注，因此本文旨在通过主动学习减少所需的人工标注数据量。</p>
<h2 id="标注数据的两种方式"><a class="markdownIt-Anchor" href="#标注数据的两种方式"></a> 标注数据的两种方式</h2>
<p>对于语义分析这一任务而言，目前主要有两种获取标注数据的方式：</p>
<ul>
<li>传统的方式首先获取自然语言句子，然后通过定义好的LF形式进行标注</li>
<li>另外一种方式，来自于一篇论文《Building a Semantic Parser Overnight》，因此称为overnight标注方法。它相当于是倒过来，先通过定义好的文法生成所有的LF，然后让标注人员将这些LF表述成自然语言查询，如下图所示：<br>
<img src="http://imglf4.nosdn0.126.net/img/Y3cva2JCQ0tUWi91TkhqKzN0OUdkSW9YRzJQbE1SWVJnUG1SZW42T3c1N1Y3VmkrblB1dW1RPT0.jpg" alt="Overnight方法"></li>
</ul>
<p>前一种传统的数据标记方式能够方便地应用到传统主动学习策略（例如least confidence、large margin、entropy based等等方式）去做sample selection。而后一种数据标记方式（overnight）由于自然语言样本x是未知的（是需要使用人力去生成的），因此就无法直接基于P(y|x)引用least confidence策略去做主动学习，因此本文主要聚焦在对于第二种标记方式（overnight）的主动学习策略的探索上。</p>
<h2 id="基础模型"><a class="markdownIt-Anchor" href="#基础模型"></a> 基础模型</h2>
<p>本文做语义分析任务的模型就是传统的seq2seq模型，使用一个双向RNN编码序列，再用一个双向RNN解码序列。训练时需要最小化的loss为负对数损失：<br>
<img src="http://imglf6.nosdn0.126.net/img/Y3cva2JCQ0tUWi91TkhqKzN0OUdkSHlYOC9iZ25qTFI1MHpxWUhYUTFZT0hWMHVaMDUzQ2pnPT0.jpg?" alt="seq2seq loss"></p>
<h2 id="主动学习方法"><a class="markdownIt-Anchor" href="#主动学习方法"></a> 主动学习方法</h2>
<h3 id="针对传统数据集的主动学习策略"><a class="markdownIt-Anchor" href="#针对传统数据集的主动学习策略"></a> 针对传统数据集的主动学习策略</h3>
<p>对于传统数据集，一个简单但有效的主动学习策略就是基于最小置信度，它是从未标注数据集中选取模型预测序列不确定性最高的样本进行标注：<br>
<img src="http://imglf6.nosdn0.126.net/img/Y3cva2JCQ0tUWi91TkhqKzN0OUdkTDd2SnVxSFh6WnNhOVpDTHFCWTEvdVdac1RndEdsL1lBPT0.jpg" alt="基于least confidence的主动学习算法"><br>
对应到上述基础模型，相当于就是从未标注数据集中选取预测的负对数损失(1)最大的样本进行标注。</p>
<p>考虑到通过最小置信度进行sample selection使用的信息过于单一，作者还尝试了训练一个分类器去预测模型生成目标LF序列错误的概率，最后选取错误概率最高的样本进行标注即可。作者使用了许多不同的特征作为分类器的输入，包括对数损失、最优和次优预测的margin、句子频度（这个没懂，原文是source sentence frequency）、编码器的最终状态、解码器的最终状态等；同时还使用了不同的分类器结构，包括逻辑回归、全连接神经网络、多层CNN等等，在已标注的数据集上进行训练，但最后（在dev数据上）发现最小置信度策略的效果和分类器是不相上下的。也就是说使用最小置信度策略，在传统的数据集上就够用了。</p>
<h3 id="针对overnight数据集的主动学习策略"><a class="markdownIt-Anchor" href="#针对overnight数据集的主动学习策略"></a> 针对overnight数据集的主动学习策略</h3>
<p>由于overnight的数据标注方式是基于给定的LF(y)去产生自然语言句子(x)，因此主动学习的任务就变成了：如何从未标注的LF集合中选取LF来获取自然语言句子，能够最快提升模型性能。</p>
<p>上面提到，由于overnight这种标注方式的特殊之处，基于P(y|x)应用least confidence的策略是不可行的，所以需要探索别的主动学习策略。</p>
<p>其中一种直观的方法是使用反向的S2S对P(x|y)进行建模，即给定LF(y)，预测自然语言(x)。这样就能基于P(x|y)应用least confidence了，如下图：<br>
<img src="http://imglf3.nosdn0.126.net/img/Y3cva2JCQ0tUWi91TkhqKzN0OUdkSHlYOC9iZ25qTFJQY0orSTdaQ3RLckkzRkpRb0M5N2V3PT0.jpg?" alt="使用反向S2S建模"><br>
但这种方法忽略了一个重要的问题，就是LF其实是自然语言的抽象表示，一个自然语言句子只对应了一个LF，但LF可能对应多个不同的自然语言句子（同一语义的多种表述），从而导致了其置信度比较低（因为有多种自然语言表述都有可能）。因此这种基于P(x|y)应用least confidence的方法是有缺陷的。</p>
<p>因此作者提出了另外一个方法：训练一个二元分类器去预测样本是否已经被选入已标记数据集中。作者使用了两组特征作为分类器的输入：</p>
<ol>
<li>LF model: 是使用LF句子训练的一个在LF上的语言模型，去对P(y)进行建模，该模型最后输出的log(P(y))将会作为分类器的特征</li>
<li>backword S2S model: 就是使用seq2seq模型去对P(x|y)进行建模，即给定LF，要求预测自然语言句子，使用的特征和上面提到的forward S2S model的类似。</li>
</ol>
<p>在针对dev数据的测试中，作者发现使用source LF frequencies和margin of best and second best solution这两种特征的融合，训练出来的分类器效果是最好的。因此最后就使用这两个特征的线性组合作为分类器。</p>
<p>PS: 这篇论文作者通篇都没有放模型图，完全就是通过语言对模型的描述…</p>
<h2 id="实验"><a class="markdownIt-Anchor" href="#实验"></a> 实验</h2>
<p><img src="http://imglf5.nosdn0.126.net/img/Y3cva2JCQ0tUWi91TkhqKzN0OUdkSHlYOC9iZ25qTFI3NEJZUHNGVEc5ZldJWjdpMXRJa09nPT0.jpg?" alt="正确率随标注样本数变化的曲线"></p>
<p>作者在三个semantic parsing的数据集进行实验，其中©就是overnight的数据集。对比试验分别采用了：1) Random - 随机selection；2) Fw S2S - 使用seq2seq模型建模P(y|x)；3) Bw S2S - 使用seq2seq模型建模P(x|y)，使用其log loss做selection；4) Bw classifier - 针对overnight数据集，上面提到的多种特征的线性组合来训练分类器。采用的评判标准是曲线下面积。</p>
<p>可以看到在图©中，Bw classifier的效果和Fw S2S很接近，证明此方法是有一定效果的。</p>
<h2 id="待思考的点"><a class="markdownIt-Anchor" href="#待思考的点"></a> 待思考的点</h2>
<ul>
<li>本文提出的第二种判别器的方法和之前讲的那种基于对抗的主动学习方法是同一种吗？若不是，它们有何不同呢？</li>
<li>前向和反向seq2seq模型，分别建模了P(y|x)和P(x|y)，从概率的意义上来讲有什么不同？这两者模型之间是否存在某种对应关系or某种程度上的等价？</li>
<li>在使用前向或反向seq2seq建模P(y|x)或者P(x|y)时，从模型的不同结点处提取出来多个特征有什么意义吗？这些特征之间包含多大程度的独立信息和冗余呢？</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">yym6472</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://yym6472.github.io/2019/04/26/《Active-Learning-for-Deep-Semantic-Parsing》阅读笔记/">https://yym6472.github.io/2019/04/26/《Active-Learning-for-Deep-Semantic-Parsing》阅读笔记/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NLP/">NLP</a><a class="post-meta__tags" href="/tags/Active-Learning/">Active Learning</a></div><div class="social-share"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2019/04/27/Github-Pages-Hexo-博客搭建记录/"><i class="fa fa-chevron-left">  </i><span>Github Pages + Hexo 博客搭建记录</span></a></div><div class="next-post pull-right"><a href="/2019/04/20/NLP领域的对抗式方法综述/"><span>NLP领域的对抗式方法综述</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '1470654ab571587d5962',
  clientSecret: 'dd25cc8b92dbedf931e5a5e29b75f6bdbcff11ed',
  repo: 'yym6472.github.io',
  owner: 'yym6472',
  admin: 'yym6472',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(https://i.loli.net/2019/04/27/5cc456373162f.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2019 By yym6472</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script src="/js/search/algolia.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>